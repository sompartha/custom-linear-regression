# 📘 Linear Regression from Scratch using Gradient Descent

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lH5eiKZYLUt6M0fTZDItokR7KdYii2mT?usp=sharing)

A minimal yet complete implementation of **Linear Regression** using **manual Gradient Descent** — built entirely from scratch using **NumPy**.  
The model is trained on the **California Housing dataset** and evaluated using standard regression metrics.

---

## ✅ Features

- 📊 Manual Gradient Descent (no sklearn model)
- 📈 Loss curve visualization across epochs
- 🔄 Feature normalization using `StandardScaler`
- 🧪 Evaluation metrics: RMSE, MAE, R² Score
- 🏡 Applied on real-world California housing prices
- 🖼️ Prediction vs. Actual visualization

---

## 🛠 Libraries Used

- `numpy` – core logic and math
- `matplotlib` – for plotting loss and predictions
- `sklearn.datasets` – load California housing dataset
- `sklearn.preprocessing` – normalize input features
- `sklearn.model_selection` – train/test split

---

## ▶️ Run This Notebook

Click the Colab badge above or open this link:  
📎 [Run on Colab](https://colab.research.google.com/drive/1lH5eiKZYLUt6M0fTZDItokR7KdYii2mT?usp=sharing)

No installation needed — runs 100% in-browser using Google Colab.

---

## 📌 Author

**Sompartha Sinha**  
🎓 BS in Data Science, IIT Madras  
🔗 [GitHub](https://github.com/somparthasinha)

---

## 📄 License

This project is open-source and available under the [MIT License](LICENSE).
